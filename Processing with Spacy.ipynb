{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b4dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = ['parser', 'ner']\n",
    "# print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file = Path('input', 'enron_mails.p')\n",
    "df = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df['text'].apply(len)\n",
    "Q1 = df['length'].quantile(0.25)\n",
    "Q3 = df['length'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# df.loc[df['length'] > (Q3 + 15 * IQR),:]\n",
    "df.sort_values(by=['length'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_vals = [132160, 480942, 337694]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(extreme_vals, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkit(df, chunk_size = 50000): \n",
    "    num_chunks = math.ceil(len(df) / chunk_size)\n",
    "    if len(df) % chunk_size != 0:\n",
    "        num_chunks += 1\n",
    "    for i in range(num_chunks):\n",
    "        yield df[i*chunk_size:(i + 1) * chunk_size].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af73db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfch = chunkit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tokens(text):\n",
    "#     doc = nlp(text)\n",
    "#     res = [token.text for token in doc]\n",
    "    \n",
    "#     return res\n",
    "\n",
    "# def get_token_lemma(text):\n",
    "#     doc = nlp(text)\n",
    "#     res = [(token, token.lemma_) for token in doc]\n",
    "    \n",
    "#     return res\n",
    "\n",
    "\n",
    "# def get_token_lemma_pos(text):\n",
    "#     doc = nlp(text)\n",
    "#     res = [(token, token.lemma_, token.pos_) for token in doc]\n",
    "    \n",
    "#     return res\n",
    "\n",
    "\n",
    "def get_tokens(doc):\n",
    "    res = [token for token in doc]\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def get_token_lemma(doc):\n",
    "    res = [(token, token.lemma_) for token in doc]\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def get_token_lemma_pos(doc):\n",
    "    res = [(str(token.text), str(token.lemma_), str(token.pos_)) for token in doc]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, chunk in enumerate(dfch):\n",
    "    nlp = spacy.load('en_core_web_sm', disable=dis)\n",
    "    docs = nlp.pipe(chunk['text'].tolist(), n_process=8)\n",
    "    chunk['doc'] = [doc for doc in nlp.pipe(chunk[\"text\"].tolist())]\n",
    "    chunk.loc[:,['id', 'doc']].to_pickle(Path('output', f'email_spacy_{i}_doc.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d21f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfch = chunkit(df)\n",
    "for i, chunk in enumerate(dfch):\n",
    "    nlp = spacy.load('en_core_web_sm', disable=dis)\n",
    "    docs = nlp.pipe(chunk['text'].tolist(), n_process=8)\n",
    "    chunk['tlp'] = [get_token_lemma_pos(doc) for doc in nlp.pipe(chunk[\"text\"].tolist())]\n",
    "    chunk.loc[:,['id', 'tlp']].to_pickle(Path('output', f'email_spacy_{i}_tlp.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['tlp'] = df['text'].apply(get_token_lemma_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = df.loc[0,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc:\n",
    "    print((ent.text, ent.lemma_, ent.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.max_length = 1650000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_s = 500\n",
    "n_p = 6\n",
    "\n",
    "docs = nlp.pipe(df['text'].tolist(), batch_size=b_s, n_process=n_p, disable=dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c989b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df[\"spacy\"] = [doc for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tok_list = []\n",
    "for doc in docs:\n",
    "    tok_list.append(get_tokens(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61958f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tok_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "t_l_list = []\n",
    "for doc in docs:\n",
    "    t_l_list.append(get_token_lemma(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006beb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tlp_list = []\n",
    "for doc in docs:\n",
    "    tlp_list.append(get_token_lemma_pos(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c4e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.loc[:2,'text']\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in next(docs):\n",
    "    print(dir(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13322ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in next(docs):\n",
    "    print((token, token.lemma_, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(dir(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc.is_nered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab972c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.loc[0,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ec3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a8d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dframcy import DframCy\n",
    "dframcy = DframCy(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a9935",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dframcy.nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "annotation_dataframe = dframcy.to_dataframe(doc)\n",
    "annotation_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eef7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1fc3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miri] *",
   "language": "python",
   "name": "conda-env-miri-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
