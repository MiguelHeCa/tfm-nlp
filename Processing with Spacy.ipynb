{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d4c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181f69a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b4dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = ['parser', 'ner']\n",
    "# print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file = Path('input', 'enron_mails.p')\n",
    "df = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df['text'].apply(len)\n",
    "Q1 = df['length'].quantile(0.25)\n",
    "Q3 = df['length'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# df.loc[df['length'] > (Q3 + 15 * IQR),:]\n",
    "df.sort_values(by=['length'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_vals = [132160, 480942, 337694]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(extreme_vals, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkit(df, chunk_size = 50000): \n",
    "    num_chunks = math.ceil(len(df) / chunk_size)\n",
    "    if len(df) % chunk_size != 0:\n",
    "        num_chunks += 1\n",
    "    for i in range(num_chunks):\n",
    "        yield df[i*chunk_size:(i + 1) * chunk_size].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af73db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfch = chunkit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tokens(text):\n",
    "#     doc = nlp(text)\n",
    "#     res = [token.text for token in doc]\n",
    "    \n",
    "#     return res\n",
    "\n",
    "# def get_token_lemma(text):\n",
    "#     doc = nlp(text)\n",
    "#     res = [(token, token.lemma_) for token in doc]\n",
    "    \n",
    "#     return res\n",
    "\n",
    "\n",
    "# def get_token_lemma_pos(text):\n",
    "#     doc = nlp(text)\n",
    "#     res = [(token, token.lemma_, token.pos_) for token in doc]\n",
    "    \n",
    "#     return res\n",
    "\n",
    "\n",
    "def get_tokens(doc):\n",
    "    res = [token for token in doc]\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def get_token_lemma(doc):\n",
    "    res = [(token, token.lemma_) for token in doc]\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def get_token_lemma_pos(doc):\n",
    "    res = [(str(token.text), str(token.lemma_), str(token.pos_)) for token in doc]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, chunk in enumerate(dfch):\n",
    "    nlp = spacy.load('en_core_web_sm', disable=dis)\n",
    "    docs = nlp.pipe(chunk['text'].tolist(), n_process=8)\n",
    "    chunk['doc'] = [doc for doc in nlp.pipe(chunk[\"text\"].tolist())]\n",
    "    chunk.loc[:,['id', 'doc']].to_pickle(Path('output', f'email_spacy_{i}_doc.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d21f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfch = chunkit(df)\n",
    "for i, chunk in enumerate(dfch):\n",
    "    nlp = spacy.load('en_core_web_sm', disable=dis)\n",
    "    docs = nlp.pipe(chunk['text'].tolist(), n_process=8)\n",
    "    chunk['tlp'] = [get_token_lemma_pos(doc) for doc in nlp.pipe(chunk[\"text\"].tolist())]\n",
    "    chunk.loc[:,['id', 'tlp']].to_pickle(Path('output', f'email_spacy_{i}_tlp.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['tlp'] = df['text'].apply(get_token_lemma_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = df.loc[0,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc:\n",
    "    print((ent.text, ent.lemma_, ent.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.max_length = 1650000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_s = 500\n",
    "n_p = 6\n",
    "\n",
    "docs = nlp.pipe(df['text'].tolist(), batch_size=b_s, n_process=n_p, disable=dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c989b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df[\"spacy\"] = [doc for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tok_list = []\n",
    "for doc in docs:\n",
    "    tok_list.append(get_tokens(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61958f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tok_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "t_l_list = []\n",
    "for doc in docs:\n",
    "    t_l_list.append(get_token_lemma(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006beb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tlp_list = []\n",
    "for doc in docs:\n",
    "    tlp_list.append(get_token_lemma_pos(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c4e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.loc[:2,'text']\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in next(docs):\n",
    "    print(dir(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13322ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in next(docs):\n",
    "    print((token, token.lemma_, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(dir(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc.is_nered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab972c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.loc[0,'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7972df06",
   "metadata": {},
   "source": [
    "# Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fbb3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = Path('/Volumes', 'tfm', 'input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d872c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacies = list(in_path.glob('**/*_tlp.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde1b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for file in spacies:\n",
    "    df = pd.read_pickle(file)\n",
    "    df_list.append(df)\n",
    "\n",
    "df_tlp = pd.concat(df_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1184de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tlp.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06355011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hernandez-j/all_documents/474.</td>\n",
       "      <td>[(----------------------, --------------------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hernandez-j/all_documents/683.</td>\n",
       "      <td>[(----------------------, --------------------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hernandez-j/all_documents/539.</td>\n",
       "      <td>[(----------------------, --------------------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hernandez-j/all_documents/315.</td>\n",
       "      <td>[(I, I, PRON), (just, just, ADV), (received, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hernandez-j/all_documents/835.</td>\n",
       "      <td>[(FYI, FYI, PROPN), (., ., PUNCT)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517396</th>\n",
       "      <td>zufferli-j/sent_items/19.</td>\n",
       "      <td>[(Sorry, sorry, INTJ), (for, for, ADP), (the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517397</th>\n",
       "      <td>zufferli-j/sent_items/68.</td>\n",
       "      <td>[(Nella, Nella, PROPN), (here, here, ADV), (is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517398</th>\n",
       "      <td>zufferli-j/sent_items/38.</td>\n",
       "      <td>[(subject, subject, NOUN), (to, to, ADP), (mec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517399</th>\n",
       "      <td>zufferli-j/sent_items/127.</td>\n",
       "      <td>[(It, it, PRON), ('s, be, AUX), (2200, 2200, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517400</th>\n",
       "      <td>zufferli-j/sent_items/64.</td>\n",
       "      <td>[(can, can, AUX), (er, er, INTJ), (make, make,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517398 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "0       hernandez-j/all_documents/474.   \n",
       "1       hernandez-j/all_documents/683.   \n",
       "2       hernandez-j/all_documents/539.   \n",
       "3       hernandez-j/all_documents/315.   \n",
       "4       hernandez-j/all_documents/835.   \n",
       "...                                ...   \n",
       "517396       zufferli-j/sent_items/19.   \n",
       "517397       zufferli-j/sent_items/68.   \n",
       "517398       zufferli-j/sent_items/38.   \n",
       "517399      zufferli-j/sent_items/127.   \n",
       "517400       zufferli-j/sent_items/64.   \n",
       "\n",
       "                                                      tlp  \n",
       "0       [(----------------------, --------------------...  \n",
       "1       [(----------------------, --------------------...  \n",
       "2       [(----------------------, --------------------...  \n",
       "3       [(I, I, PRON), (just, just, ADV), (received, r...  \n",
       "4                      [(FYI, FYI, PROPN), (., ., PUNCT)]  \n",
       "...                                                   ...  \n",
       "517396  [(Sorry, sorry, INTJ), (for, for, ADP), (the, ...  \n",
       "517397  [(Nella, Nella, PROPN), (here, here, ADV), (is...  \n",
       "517398  [(subject, subject, NOUN), (to, to, ADP), (mec...  \n",
       "517399  [(It, it, PRON), ('s, be, AUX), (2200, 2200, N...  \n",
       "517400  [(can, can, AUX), (er, er, INTJ), (make, make,...  \n",
       "\n",
       "[517398 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecfed1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('----------------------', '----------------------', 'PUNCT'),\n",
       " ('Forwarded', 'forward', 'VERB'),\n",
       " ('by', 'by', 'ADP'),\n",
       " ('Maria', 'Maria', 'PROPN'),\n",
       " ('Sandoval', 'Sandoval', 'PROPN'),\n",
       " ('/', '/', 'SYM'),\n",
       " ('HOU', 'HOU', 'PROPN'),\n",
       " ('/', '/', 'SYM'),\n",
       " ('ECT', 'ECT', 'PROPN'),\n",
       " ('on', 'on', 'ADP'),\n",
       " ('11/09/2000=20', '11/09/2000=20', 'NUM'),\n",
       " ('\\n', '\\n', 'SPACE'),\n",
       " ('02:59', '02:59', 'NUM'),\n",
       " ('PM', 'pm', 'NOUN'),\n",
       " ('---------------------------', '---------------------------', 'PUNCT'),\n",
       " ('\\n  ', '\\n  ', 'SPACE'),\n",
       " ('=', '=', 'SYM'),\n",
       " ('20', '20', 'NUM')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tlp.loc[0,'tlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a9a5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tlp['fq_tlp'] = df_tlp['tlp'].apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1443ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tlp.to_pickle(Path('/Volumes', 'tfm', 'input', 'email_spacy_tlp.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e2f1a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Volumes/tfm/input/email_spacy_2_tlp.pkl'),\n",
       " PosixPath('/Volumes/tfm/input/email_spacy_11_tlp.pkl'),\n",
       " PosixPath('/Volumes/tfm/input/email_spacy_4_tlp.pkl'),\n",
       " PosixPath('/Volumes/tfm/input/email_spacy_10_tlp.pkl'),\n",
       " PosixPath('/Volumes/tfm/input/email_spacy_0_tlp.pkl'),\n",
       " PosixPath('/Volumes/tfm/input/email_spacy_9_tlp.pkl'),\n",
       " PosixPath('/Volumes/tfm/input/email_spacy_8_tlp.pkl'),\n",
       " PosixPath('/Volumes/tfm/input/email_spacy_3_tlp.pkl'),\n",
       " PosixPath('/Volumes/tfm/input/email_spacy_6_tlp.pkl'),\n",
       " PosixPath('/Volumes/tfm/input/email_spacy_5_tlp.pkl'),\n",
       " PosixPath('/Volumes/tfm/input/email_spacy_7_tlp.pkl'),\n",
       " PosixPath('/Volumes/tfm/input/email_spacy_1_tlp.pkl')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3f9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miri] *",
   "language": "python",
   "name": "conda-env-miri-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
