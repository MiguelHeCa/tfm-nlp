{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080d4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import io\n",
    "\n",
    "import pyfreeling\n",
    "\n",
    "import os\n",
    "from email.parser import Parser\n",
    "import email.utils\n",
    "\n",
    "import time\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb49da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"../maildir/lay-k\"  # Change root dir to affect how many mails are touched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24cfa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messageIDtoSubject(mail_dict, messageID):\n",
    "    return mail_dict[messageID][\"subject\"].replace(\" \", \"\")\n",
    "\n",
    "\n",
    "def raw_parse(inputfile, email_list):\n",
    "    with open(inputfile, \"r\",encoding=\"utf-8\",errors=\"ignore\") as f:\n",
    "        data = f.read()\n",
    "    parsedEmail = Parser().parsestr(data)\n",
    "    timestamp = time.mktime(email.utils.parsedate(parsedEmail[\"date\"]))\n",
    "    email_list.append((timestamp, parsedEmail))\n",
    "\n",
    "\n",
    "def obtain_raw_threads(mail_dict, email_list):\n",
    "    subject_dict = {}\n",
    "    rootMailSet = set()\n",
    "    auxiliarRootStructure = {}\n",
    "\n",
    "    for mail in email_list:\n",
    "        actualEmail = mail[1]\n",
    "        true_subject = actualEmail['subject']\n",
    "        true_subject = true_subject.replace(\" \", \"\")\n",
    "        mail_dict[actualEmail[\"message-id\"]] = actualEmail\n",
    "        if \"Re:\" != true_subject[0:3]:\n",
    "            auxiliarRootStructure[true_subject] = actualEmail[\"message-id\"]\n",
    "            if true_subject not in subject_dict:\n",
    "                subject_dict[true_subject] = []\n",
    "        else:\n",
    "            new_subject = true_subject.replace(\"Re:\", \"\")\n",
    "            if new_subject in subject_dict:\n",
    "                subject_dict[new_subject].append(actualEmail[\"message-id\"])\n",
    "                rootMailSet.add(auxiliarRootStructure[new_subject])\n",
    "            subject_dict[true_subject] = []\n",
    "    threads = {}\n",
    "    for mail in rootMailSet:\n",
    "        subject = messageIDtoSubject(mail_dict, mail)\n",
    "        childThread = subject_dict[subject]\n",
    "        threads[mail] = childThread\n",
    "    return threads\n",
    "\n",
    "\n",
    "def preprocess_recipients(recipient):\n",
    "    if recipient is not None:\n",
    "        users = re.sub(r'\\s+', '', recipient).split(',')\n",
    "        if len(users) > 1:\n",
    "            return users\n",
    "        else:\n",
    "            return users[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def obtain_features(email_list):\n",
    "    email_dict = {}\n",
    "    for num, mail in email_list:\n",
    "        email_dict[mail['message-id']] = {\n",
    "            'from': mail['from'],\n",
    "            'to': preprocess_recipients(mail['to']),\n",
    "            'date': mail['date'],\n",
    "            'features': {}\n",
    "        }\n",
    "    return email_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0e0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "email_list = []\n",
    "\n",
    "for directory, subdirectory, filenames in os.walk(basedir):\n",
    "    for filename in filenames:\n",
    "        raw_parse(os.path.join(directory, filename), email_list)\n",
    "email_list.sort(key=lambda x: x[0])\n",
    "\n",
    "mail_dict = obtain_features(email_list)\n",
    "\n",
    "pureThreads = obtain_raw_threads(mail_dict, email_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b721dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'en'\n",
    "# Check whether we know where to find FreeLing data files\n",
    "if \"FREELINGDIR\" not in os.environ:\n",
    "    if sys.platform == \"win32\" or sys.platform == \"win64\":\n",
    "        os.environ[\"FREELINGDIR\"] = \"C:\\\\Program Files\"\n",
    "    else:\n",
    "        os.environ[\"FREELINGDIR\"] = \"/usr/local\"\n",
    "    print(\n",
    "        f\"FREELINGDIR environment variable not defined, trying \",\n",
    "        os.environ[\"FREELINGDIR\"],\n",
    "        file=sys.stderr,\n",
    "    )\n",
    "\n",
    "if not os.path.exists(os.environ[\"FREELINGDIR\"] + \"/share/freeling\"):\n",
    "    print(\n",
    "        \"Folder\",\n",
    "        os.environ[\"FREELINGDIR\"] + \"/share/freeling\",\n",
    "        \"not found.\\n\"\n",
    "        + \"Please set FREELINGDIR environment variable to FreeLing installation directory\",\n",
    "        file=sys.stderr,\n",
    "    )\n",
    "    sys.exit(1)\n",
    "\n",
    "# Location of FreeLing configuration files.\n",
    "DATA = os.environ[\"FREELINGDIR\"] + \"/share/freeling/\"\n",
    "\n",
    "# Init locales\n",
    "pyfreeling.util_init_locale(\"default\")\n",
    "\n",
    "# create options set for maco analyzer.\n",
    "# Default values are Ok, except for data files.\n",
    "LANG = lang\n",
    "op = pyfreeling.maco_options(LANG)\n",
    "op.set_data_files(\n",
    "    \"\",\n",
    "    DATA + \"common/punct.dat\",\n",
    "    DATA + LANG + \"/dicc.src\",\n",
    "    DATA + LANG + \"/afixos.dat\",\n",
    "    \"\",\n",
    "    DATA + LANG + \"/locucions.dat\",\n",
    "    DATA + LANG + \"/np.dat\",\n",
    "    DATA + LANG + \"/quantities.dat\",\n",
    "    DATA + LANG + \"/probabilitats.dat\",\n",
    ")\n",
    "\n",
    "# create analyzers\n",
    "tk = pyfreeling.tokenizer(DATA + LANG + \"/tokenizer.dat\")\n",
    "sp = pyfreeling.splitter(DATA + LANG + \"/splitter.dat\")\n",
    "sid = sp.open_session()\n",
    "mf = pyfreeling.maco(op)\n",
    "\n",
    "# activate morpho modules to be used in next call\n",
    "mf.set_active_options(\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    True,  # select which among created\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,  # submodules are to be used.\n",
    "    True,\n",
    "    True,\n",
    "    True,\n",
    "    True,\n",
    ")\n",
    "# default: all created submodules are used\n",
    "\n",
    "# create tagger, sense anotator, and parsers\n",
    "tg = pyfreeling.hmm_tagger(DATA + LANG + \"/tagger.dat\", True, 2)\n",
    "sen = pyfreeling.senses(DATA + LANG + \"/senses.dat\")\n",
    "dep = pyfreeling.dep_lstm(DATA + LANG + \"/dep_lstm/params-en.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35de7200",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = email_list[0][1].get_payload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38c90503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter dictated by Ken Lay\n",
      "\n",
      "\n",
      "\n",
      "Hello Janice:\n",
      "\n",
      " I enjoyed your recent e-mail but was sorry to hear about your dad.  It \n",
      "sounds as though his health has deteriorated significantly.  These are always \n",
      "difficult times.  As I watched my mother and father's health deteriorate and \n",
      "ultimately watched them die, it is a very defining time in our lives.  But we \n",
      "can be very thankful to have such great parents and to have been privilege to \n",
      "be raised in such loving homes.\n",
      "\n",
      " Sounds as though Eric has done very well as SMSU.  He is joining an \n",
      "excellent company.  I am also delighted to hear that he will continue his \n",
      "education working toward an MBA.  As we are living in an age were \n",
      "intellectual capital is so valuable, it is important for every young person \n",
      "to obtain the very best possible education they can.  As to our family, \n",
      "within the last ten days our youngest daughter Elizabeth was married to a \n",
      "young man from Buenos Aires, Argentina.  They met while they were both \n",
      "working on a project as lawyers in Buenos Aires.  They're currently on their \n",
      "honeymoon but shortly after returning will be moving from Buenos Aires to \n",
      "Miami, Florida.  This past Thursday night our sixth grandchild was born.  It \n",
      "was born to our son David and his wife Courtney.  It was a 7 lb., 10 oz.,  20 \n",
      "inch little boy.  So we now have three grandsons and three granddaughters \n",
      "ranging from about 2 years - 4 months down to a few days.  They are a great \n",
      "deal of fun.  We are doing quite well.  I am looking forward to seeing Ginger \n",
      "\"Rees\" Copeland when she comes to Houston.  I would be delighted to arrange \n",
      "tickets for you and your family should you ever have occasion to visit \n",
      "Houston.\n",
      "\n",
      " I hope you have a great summer.\n",
      "\n",
      "\n",
      "\n",
      "cc:  Bonnie Bourne\n",
      "        Sharon Lay\n"
     ]
    }
   ],
   "source": [
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57a30e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter dictated by Ken Lay\n",
      "\n",
      "Hello Janice:\n",
      "\n",
      " I enjoyed your recent e-mail but was sorry to hear about your dad.  It \n",
      "\n",
      "sounds as though his health has deteriorated significantly.  These are always \n",
      "\n",
      "difficult times.  As I watched my mother and father's health deteriorate and \n",
      "\n",
      "ultimately watched them die, it is a very defining time in our lives.  But we \n",
      "\n",
      "can be very thankful to have such great parents and to have been privilege to \n",
      "\n",
      "be raised in such loving homes.\n",
      "\n",
      " Sounds as though Eric has done very well as SMSU.  He is joining an \n",
      "\n",
      "excellent company.  I am also delighted to hear that he will continue his \n",
      "\n",
      "education working toward an MBA.  As we are living in an age were \n",
      "\n",
      "intellectual capital is so valuable, it is important for every young person \n",
      "\n",
      "to obtain the very best possible education they can.  As to our family, \n",
      "\n",
      "within the last ten days our youngest daughter Elizabeth was married to a \n",
      "\n",
      "young man from Buenos Aires, Argentina.  They met while they were both \n",
      "\n",
      "working on a project as lawyers in Buenos Aires.  They're currently on their \n",
      "\n",
      "honeymoon but shortly after returning will be moving from Buenos Aires to \n",
      "\n",
      "Miami, Florida.  This past Thursday night our sixth grandchild was born.  It \n",
      "\n",
      "was born to our son David and his wife Courtney.  It was a 7 lb., 10 oz.,  20 \n",
      "\n",
      "inch little boy.  So we now have three grandsons and three granddaughters \n",
      "\n",
      "ranging from about 2 years - 4 months down to a few days.  They are a great \n",
      "\n",
      "deal of fun.  We are doing quite well.  I am looking forward to seeing Ginger \n",
      "\n",
      "\"Rees\" Copeland when she comes to Houston.  I would be delighted to arrange \n",
      "\n",
      "tickets for you and your family should you ever have occasion to visit \n",
      "\n",
      "Houston.\n",
      "\n",
      " I hope you have a great summer.\n",
      "\n",
      "cc:  Bonnie Bourne\n",
      "\n",
      "        Sharon Lay\n"
     ]
    }
   ],
   "source": [
    "for lin in io.StringIO(msg):\n",
    "    if lin != '\\n':\n",
    "        print(lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64752308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc   cc\n",
      ":   :\n",
      "Bonnie_Bourne_Sharon_Lay_Letter   bonnie_bourne_sharon_lay_letter\n",
      "dictated   dictate\n",
      "by   by\n",
      "Ken_Lay_Hello_Janice   ken_lay_hello_janice\n",
      ":   :\n",
      "I   i\n",
      "enjoyed   enjoy\n",
      "your   your\n",
      "recent   recent\n",
      "e-mail   email\n",
      "but   but\n",
      "was   be\n",
      "sorry   sorry\n",
      "to   to\n",
      "hear   hear\n",
      "about   about\n",
      "your   your\n",
      "dad   dad\n",
      ".   .\n",
      "It   it\n",
      "sounds   sound\n",
      "as   as\n",
      "though   though\n",
      "his   his\n",
      "health   health\n",
      "has   have\n",
      "deteriorated   deteriorate\n",
      "significantly   significantly\n",
      ".   .\n",
      "These   these\n",
      "are   be\n",
      "always   always\n",
      "difficult   difficult\n",
      "times   time\n",
      ".   .\n",
      "As   as\n",
      "I   i\n",
      "watched   watch\n",
      "my   my\n",
      "mother   mother\n",
      "and   and\n",
      "father   father\n",
      "'s   's\n",
      "health   health\n",
      "deteriorate   deteriorate\n",
      "and   and\n",
      "ultimately   ultimately\n",
      "watched   watch\n",
      "them   them\n",
      "die   die\n",
      ",   ,\n",
      "it   it\n",
      "is   be\n",
      "a   a\n",
      "very   very\n",
      "defining   define\n",
      "time   time\n",
      "in   in\n",
      "our   our\n",
      "lives   life\n",
      ".   .\n",
      "But   but\n",
      "we   we\n",
      "can   can\n",
      "be   be\n",
      "very   very\n",
      "thankful   thankful\n",
      "to   to\n",
      "have   have\n",
      "such   such\n",
      "great   great\n",
      "parents   parent\n",
      "and   and\n",
      "to   to\n",
      "have   have\n",
      "been   be\n",
      "privilege   privilege\n",
      "to   to\n",
      "be   be\n",
      "raised   raise\n",
      "in   in\n",
      "such   such\n",
      "loving   love\n",
      "homes   home\n",
      ".   .\n",
      "Sounds   sound\n",
      "as   as\n",
      "though   though\n",
      "Eric   eric\n",
      "has   have\n",
      "done   do\n",
      "very   very\n",
      "well   well\n",
      "as   as\n",
      "SMSU   smsu\n",
      ".   .\n",
      "He   he\n",
      "is   be\n",
      "joining   join\n",
      "an   a\n",
      "excellent   excellent\n",
      "company   company\n",
      ".   .\n",
      "I   i\n",
      "am   be\n",
      "also   also\n",
      "delighted   delight\n",
      "to   to\n",
      "hear   hear\n",
      "that   that\n",
      "he   he\n",
      "will   will\n",
      "continue   continue\n",
      "his   his\n",
      "education   education\n",
      "working   work\n",
      "toward   toward\n",
      "an   a\n",
      "MBA   mba\n",
      ".   .\n",
      "As   as\n",
      "we   we\n",
      "are   be\n",
      "living   live\n",
      "in   in\n",
      "an   a\n",
      "age   age\n",
      "were   be\n",
      "intellectual   intellectual\n",
      "capital   capital\n",
      "is   be\n",
      "so   so\n",
      "valuable   valuable\n",
      ",   ,\n",
      "it   it\n",
      "is   be\n",
      "important   important\n",
      "for   for\n",
      "every   every\n",
      "young   young\n",
      "person   person\n",
      "to   to\n",
      "obtain   obtain\n",
      "the   the\n",
      "very   very\n",
      "best   well\n",
      "possible   possible\n",
      "education   education\n",
      "they   they\n",
      "can   can\n",
      ".   .\n",
      "As   as\n",
      "to   to\n",
      "our   our\n",
      "family   family\n",
      ",   ,\n",
      "within   within\n",
      "the   the\n",
      "last   last\n",
      "ten   10\n",
      "days   day\n",
      "our   our\n",
      "youngest   young\n",
      "daughter   daughter\n",
      "Elizabeth   elizabeth\n",
      "was   be\n",
      "married   marry\n",
      "to   to\n",
      "a   a\n",
      "young   young\n",
      "man   man\n",
      "from   from\n",
      "Buenos_Aires   buenos_aires\n",
      ",   ,\n",
      "Argentina   argentina\n",
      ".   .\n",
      "They   they\n",
      "met   meet\n",
      "while   while\n",
      "they   they\n",
      "were   be\n",
      "both   both\n",
      "working   work\n",
      "on   on\n",
      "a   a\n",
      "project   project\n",
      "as   as\n",
      "lawyers   lawyer\n",
      "in   in\n",
      "Buenos_Aires   buenos_aires\n",
      ".   .\n",
      "They   they\n",
      "are   be\n",
      "currently   currently\n",
      "on   on\n",
      "their   their\n",
      "honeymoon   honeymoon\n",
      "but   but\n",
      "shortly   shortly\n",
      "after   after\n",
      "returning   return\n",
      "will   will\n",
      "be   be\n",
      "moving   move\n",
      "from   from\n",
      "Buenos_Aires   buenos_aires\n",
      "to   to\n",
      "Miami   miami\n",
      ",   ,\n",
      "Florida   florida\n",
      ".   .\n",
      "This   this\n",
      "past_Thursday_night   [J:??/??/??:??.??:pm]\n",
      "our   our\n",
      "sixth   6\n",
      "grandchild   grandchild\n",
      "was   be\n",
      "born   bear\n",
      ".   .\n",
      "It   it\n",
      "was   be\n",
      "born   bear\n",
      "to   to\n",
      "our   our\n",
      "son   son\n",
      "David   david\n",
      "and   and\n",
      "his   his\n",
      "wife   wife\n",
      "Courtney   courtney\n",
      ".   .\n",
      "It   it\n",
      "was   be\n",
      "a   a\n",
      "7   7\n",
      "lb.   lb.\n",
      ",   ,\n",
      "10   10\n",
      "oz.   oz.\n",
      ",   ,\n",
      "20_inch   LN_in:20\n",
      "little   little\n",
      "boy   boy\n",
      ".   .\n",
      "So   so\n",
      "we   we\n",
      "now   now\n",
      "have   have\n",
      "three   3\n",
      "grandsons   grandson\n",
      "and   and\n",
      "three   3\n",
      "granddaughters   granddaughter\n",
      "ranging   range\n",
      "from   from\n",
      "about   about\n",
      "2   2\n",
      "years   year\n",
      "-   -\n",
      "4   4\n",
      "months   month\n",
      "down   down\n",
      "to   to\n",
      "a   a\n",
      "few   few\n",
      "days   day\n",
      ".   .\n",
      "They   they\n",
      "are   be\n",
      "a   a\n",
      "great   great\n",
      "deal   deal\n",
      "of   of\n",
      "fun   fun\n",
      ".   .\n",
      "We   we\n",
      "are   be\n",
      "doing   do\n",
      "quite   quite\n",
      "well   well\n",
      ".   .\n",
      "I   i\n",
      "am   be\n",
      "looking   look\n",
      "forward   forward\n",
      "to   to\n",
      "seeing   see\n",
      "Ginger   ginger\n",
      "\"   \"\n",
      "Rees   rees\n",
      "\"   \"\n",
      "Copeland   copeland\n",
      "when   when\n",
      "she   she\n",
      "comes   come\n",
      "to   to\n",
      "Houston   houston\n",
      ".   .\n",
      "I   i\n",
      "would   would\n",
      "be   be\n",
      "delighted   delight\n",
      "to   to\n",
      "arrange   arrange\n",
      "tickets   ticket\n",
      "for   for\n",
      "you   you\n",
      "and   and\n",
      "your   your\n",
      "family   family\n",
      "should   should\n",
      "you   you\n",
      "ever   ever\n",
      "have   have\n",
      "occasion   occasion\n",
      "to   to\n",
      "visit   visit\n",
      "Houston   houston\n",
      ".   .\n",
      "I   i\n",
      "hope   hope\n",
      "you   you\n",
      "have   have\n",
      "a   a\n",
      "great   great\n",
      "summer   summer\n",
      ".   .\n"
     ]
    }
   ],
   "source": [
    "for lin in io.StringIO(msg):\n",
    "    if lin != '\\n':\n",
    "        l = tk.tokenize(lin)\n",
    "        ls = sp.split(sid, l, False)\n",
    "\n",
    "        ls = mf.analyze(ls)\n",
    "        ls = tg.analyze(ls)\n",
    "        ls = sen.analyze(ls)\n",
    "        ls = dep.analyze(ls)\n",
    "        # output results\n",
    "        for s in ls:\n",
    "            ws = s.get_words()\n",
    "            for w in ws:\n",
    "                print(w.get_form(), ' ', w.get_lemma())\n",
    "        #    for w in ws:\n",
    "        #        print(\n",
    "        #            w.get_form()\n",
    "        #           + \" \"\n",
    "        #           + w.get_lemma()\n",
    "        #           + \" \"\n",
    "        #           + w.get_tag()\n",
    "        #           + \" \"\n",
    "        #           + w.get_senses_string()\n",
    "        #       )\n",
    "        #   print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32023b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ls)        \n",
    "        # output results\n",
    "        #for s in ls:\n",
    "        #    ws = s.get_words()\n",
    "        #    for w in ws:\n",
    "        #        print(\n",
    "        #            w.get_form()\n",
    "        #           + \" \"\n",
    "        #           + w.get_lemma()\n",
    "        #           + \" \"\n",
    "        #           + w.get_tag()\n",
    "        #           + \" \"\n",
    "        #           + w.get_senses_string()\n",
    "        #       )\n",
    "        #   print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0de084",
   "metadata": {},
   "outputs": [],
   "source": [
    "class freeling_analyzer(object):\n",
    "    def __init__(self, folder, lang):\n",
    "        self.folder = folder\n",
    "        self.lang = lang\n",
    "        self.tk = None\n",
    "        self.sp = None\n",
    "        self.sid = None\n",
    "        self.mf = None\n",
    "        self.tg = None\n",
    "        self.sen = None\n",
    "        self.dep = None\n",
    "\n",
    "    # ------------  output a parse tree ------------\n",
    "    def printTree(self, ptree, depth):\n",
    "\n",
    "        node = ptree.begin()\n",
    "\n",
    "        print(\"\".rjust(depth * 2), end=\"\")\n",
    "        info = node.get_info()\n",
    "        if info.is_head():\n",
    "            print(\"+\", end=\"\")\n",
    "\n",
    "        nch = node.num_children()\n",
    "        if nch == 0:\n",
    "            w = info.get_word()\n",
    "            print(\n",
    "                \"({0} {1} {2})\".format(w.get_form(), w.get_lemma(), w.get_tag()), end=\"\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            print(\"{0}_[\".format(info.get_label()))\n",
    "\n",
    "            for i in range(nch):\n",
    "                child = node.nth_child_ref(i)\n",
    "                self.printTree(child, depth + 1)\n",
    "\n",
    "            print(\"\".rjust(depth * 2), end=\"\")\n",
    "            print(\"]\", end=\"\")\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "    # ------------  output a parse tree ------------\n",
    "    def printDepTree(self, dtree, depth):\n",
    "\n",
    "        node = dtree.begin()\n",
    "\n",
    "        print(\"\".rjust(depth * 2), end=\"\")\n",
    "\n",
    "        info = node.get_info()\n",
    "        print(info.get_label() + \"/\", end=\"\")\n",
    "\n",
    "        w = node.get_info().get_word()\n",
    "        print(\"({0} {1} {2})\".format(w.get_form(), w.get_lemma(), w.get_tag()), end=\"\")\n",
    "\n",
    "        nch = node.num_children()\n",
    "        if nch > 0:\n",
    "            print(\" [\")\n",
    "\n",
    "            for i in range(nch):\n",
    "                d = node.nth_child_ref(i)\n",
    "                if not d.begin().get_info().is_chunk():\n",
    "                    self.printDepTree(d, depth + 1)\n",
    "\n",
    "            ch = {}\n",
    "            for i in range(nch):\n",
    "                d = node.nth_child_ref(i)\n",
    "                if d.begin().get_info().is_chunk():\n",
    "                    ch[d.begin().get_info().get_chunk_ord()] = d\n",
    "\n",
    "            for i in sorted(ch.keys()):\n",
    "                self.printDepTree(ch[i], depth + 1)\n",
    "\n",
    "            print(\"\".rjust(depth * 2), end=\"\")\n",
    "            print(\"]\", end=\"\")\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "    def setup(self):\n",
    "        # Check whether we know where to find FreeLing data files\n",
    "        if \"FREELINGDIR\" not in os.environ:\n",
    "            if sys.platform == \"win32\" or sys.platform == \"win64\":\n",
    "                os.environ[\"FREELINGDIR\"] = \"C:\\\\Program Files\"\n",
    "            else:\n",
    "                os.environ[\"FREELINGDIR\"] = \"/usr/local\"\n",
    "            print(\n",
    "                \"FREELINGDIR environment variable not defined, trying \",\n",
    "                os.environ[\"FREELINGDIR\"],\n",
    "                file=sys.stderr,\n",
    "            )\n",
    "\n",
    "        if not os.path.exists(os.environ[\"FREELINGDIR\"] + \"/share/freeling\"):\n",
    "            print(\n",
    "                \"Folder\",\n",
    "                os.environ[\"FREELINGDIR\"] + \"/share/freeling\",\n",
    "                \"not found.\\n\"\n",
    "                + \"Please set FREELINGDIR environment variable to FreeLing installation directory\",\n",
    "                file=sys.stderr,\n",
    "            )\n",
    "            sys.exit(1)\n",
    "\n",
    "        # Location of FreeLing configuration files.\n",
    "        DATA = os.environ[\"FREELINGDIR\"] + \"/share/freeling/\"\n",
    "\n",
    "        # Init locales\n",
    "        pyfreeling.util_init_locale(\"default\")\n",
    "\n",
    "        # create options set for maco analyzer.\n",
    "        # Default values are Ok, except for data files.\n",
    "        LANG = self.lang\n",
    "        op = pyfreeling.maco_options(LANG)\n",
    "        op.set_data_files(\n",
    "            \"\",\n",
    "            DATA + \"common/punct.dat\",\n",
    "            DATA + LANG + \"/dicc.src\",\n",
    "            DATA + LANG + \"/afixos.dat\",\n",
    "            \"\",\n",
    "            DATA + LANG + \"/locucions.dat\",\n",
    "            DATA + LANG + \"/np.dat\",\n",
    "            DATA + LANG + \"/quantities.dat\",\n",
    "            DATA + LANG + \"/probabilitats.dat\",\n",
    "        )\n",
    "\n",
    "        # create analyzers\n",
    "        self.tk = pyfreeling.tokenizer(DATA + LANG + \"/tokenizer.dat\")\n",
    "        self.sp = pyfreeling.splitter(DATA + LANG + \"/splitter.dat\")\n",
    "        self.sid = self.sp.open_session()\n",
    "        self.mf = pyfreeling.maco(op)\n",
    "\n",
    "        # activate morpho modules to be used in next call\n",
    "        self.mf.set_active_options(\n",
    "            False,\n",
    "            True,\n",
    "            True,\n",
    "            True,  # select which among created\n",
    "            True,\n",
    "            True,\n",
    "            False,\n",
    "            True,  # submodules are to be used.\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "        )\n",
    "        # default: all created submodules are used\n",
    "\n",
    "        # create tagger, sense anotator, and parsers\n",
    "        self.tg = pyfreeling.hmm_tagger(DATA + LANG + \"/tagger.dat\", True, 2)\n",
    "        self.sen = pyfreeling.senses(DATA + LANG + \"/senses.dat\")\n",
    "        self.dep = pyfreeling.dep_lstm(DATA + LANG + \"/dep_lstm/params-en.dat\")\n",
    "\n",
    "    def process(self, msg):\n",
    "        for lin in io.StringIO(msg):\n",
    "            l = self.tk.tokenize(lin)\n",
    "            ls = self.sp.split(self.sid, l, False)\n",
    "\n",
    "            ls = self.mf.analyze(ls)\n",
    "            ls = self.tg.analyze(ls)\n",
    "            ls = self.sen.analyze(ls)\n",
    "            ls = self.dep.analyze(ls)\n",
    "\n",
    "            # output results\n",
    "            for s in ls:\n",
    "                ws = s.get_words()\n",
    "                for w in ws:\n",
    "                    print(\n",
    "                        w.get_form()\n",
    "                        + \" \"\n",
    "                        + w.get_lemma()\n",
    "                        + \" \"\n",
    "                        + w.get_tag()\n",
    "                        + \" \"\n",
    "                        + w.get_senses_string()\n",
    "                    )\n",
    "                print(\"\")\n",
    "\n",
    "                dp = s.get_dep_tree()\n",
    "                self.printDepTree(dp, 0)\n",
    "\n",
    "        # clean up\n",
    "        self.sp.close_session(self.sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58cf20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bbe67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b1e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30435be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfm] *",
   "language": "python",
   "name": "conda-env-tfm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
