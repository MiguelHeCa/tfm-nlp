{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13871434-25c6-420d-ae88-108a1d0c1244",
   "metadata": {},
   "source": [
    "# TF-IDF Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34dece66-2cbb-4c69-9063-ea086298ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle as pkl\n",
    "import re\n",
    "\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.metrics import pairwise_distances\n",
    "from dist_matrix.cuda_dist_matrix_full import dist_matrix as gpu_dist_matrix\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.matutils import corpus2dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573533f5-9151-4701-a3f7-268f6d2be5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(Path.cwd().parent, 'data/interim')\n",
    "tfi_dir = Path(data_dir, 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b00346f7-9a2e-443c-bbac-62bc14f5330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(msg):\n",
    "    tokens = msg.lower().strip().split()\n",
    "    clean_tokens = [t for t in tokens if re.match(r'[^\\W\\d]*$', t)]\n",
    "    clean_s = ' '.join(clean_tokens)\n",
    "    return clean_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64858f58-501a-499e-aba5-029514689e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/miguel/Projects/tfm-nlp/data/interim/parsed_emails_chains_eq_2.pkl\n",
      "/home/miguel/Projects/tfm-nlp/data/interim/parsed_emails_chains_ge_10.pkl\n",
      "/home/miguel/Projects/tfm-nlp/data/interim/parsed_emails_chains_ge_4_lt_10.pkl\n",
      "/home/miguel/Projects/tfm-nlp/data/interim/parsed_emails_chains_eq_3.pkl\n"
     ]
    }
   ],
   "source": [
    "for path in data_dir.glob('parsed_*'):\n",
    "    print(path)\n",
    "#     dataset = pd.read_pickle(path)\n",
    "#     messages = dataset['Message'].dropna().apply(lambda s: clean_string(s))\n",
    "#     tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "#     X = tfidf_vectorizer.fit_transform(messages)\n",
    "\n",
    "#     if not Path(tfi_dir, f'tfidf_normal_{path.stem[14:]}.npy').is_file():\n",
    "#         cp.save(Path(tfi_dir, f'tfidf_normal_{path.stem[14:]}.npy'), X)\n",
    "        \n",
    "#     metric = 'wmd'\n",
    "#     weights = np.ones(X.shape, dtype=np.float64)\n",
    "\n",
    "#     X = gpu_dist_matrix(X, V=X, U_weights=weights, V_weights=weights, metric='wasserstein')\n",
    "\n",
    "#     if not Path(data_dir, metric, f'tfidf_{metric}_{path.stem[14:]}.npy').is_file():\n",
    "#         np.save(Path(data_dir, metric, f'tfidf_{metric}_{path.stem[14:]}.npy'), X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88f5c1-b915-447b-9088-eb6d565c8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in data_dir.glob('parsed_*'):\n",
    "    dataset = pd.read_pickle(path)\n",
    "    messages = dataset['Message'].dropna().apply(lambda s: clean_string(s))\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = tfidf_vectorizer.fit_transform(messages)\n",
    "\n",
    "    if not Path(tfi_dir, f'tfidf_normal_{path.stem[14:]}.npy').is_file():\n",
    "        cp.save(Path(tfi_dir, f'tfidf_normal_{path.stem[14:]}.npy'), X)\n",
    "\n",
    "    metric = 'wmd'\n",
    "    X = pairwise_distances(X, metric=metric)\n",
    "\n",
    "    if not Path(data_dir, metric, f'tfidf_{metric}_{path.stem[14:]}.npy').is_file():\n",
    "        np.save(Path(data_dir, metric, f'tfidf_{metric}_{path.stem[14:]}.npy'), X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd7cb47-dcfa-418e-9392-5ac6ad55b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in data_dir.glob('parsed_*'):\n",
    "    print(f'tfidf_normal_{path.stem[14:]}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d081d-8edf-4991-8e22-ea7ab886ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [pd.read_pickle(path) for path in data_dir.glob('parsed_*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b34567-3ee4-4bad-bd8f-45d545430f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = datasets[0]['Message'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea402a9c-bd6a-4e09-8030-d62d4641d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cln_msg = [clean_string(string) for string in messages] \n",
    "cln_msg = messages.apply(lambda x: clean_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af91d0-eabb-4463-b5b2-d6f94a6fa125",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = tfidf_vectorizer.fit_transform(cln_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4926f-d3ae-4f96-80e2-2ed9c6f6c8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9879b8-df6d-40e2-89fd-0d8093bd1b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3)\n",
    "km.fit(X)\n",
    "labels = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9fcd7-82e8-43b3-bec0-5dbf3f7f83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de4c3f-f994-4fb3-abf6-d0de355d8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_trf\", disable=[\"tok2vec\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f787e888-4f7a-4f41-aa57-8e0b0ac0c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tfidf(data, file_name, file_content='corpus'):\n",
    "    file = Path(tfi_dir, f\"tfidf_{file_content}_{filename}\")\n",
    "    with open(file, 'wb') as handle:\n",
    "        pkl.dump(terms, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    print(f'File {file} saved.')\n",
    "\n",
    "\n",
    "def get_terms(string):\n",
    "    terms = []\n",
    "    for token in nlp(string):\n",
    "        if not token.is_stop and not token.is_punct and not token.is_space\\\n",
    "        and not token.like_url and not token.like_email and not token.is_currency\\\n",
    "        and not token.like_num and token.pos_ != 'X' and not token.is_digit\\\n",
    "        and token.is_alpha:\n",
    "            terms.append(f'{token}_{token.pos_}_{token.lemma_}')\n",
    "    \n",
    "    return terms\n",
    "\n",
    "\n",
    "def preprocess_terms(data, file_name):\n",
    "    file = Path(tfi_dir, f\"terms_{file_name}\")\n",
    "    print(f'Obtaining terms in mode form_pos_lemma for file {file}')\n",
    "    if file.is_file():\n",
    "        print(f'File exists, loading terms')\n",
    "        with open(file, 'rb') as handle:\n",
    "            terms = pkl.load(handle)\n",
    "    else:\n",
    "        terms = [get_terms(message) for message in data]\n",
    "        with open(file, 'wb') as handle:\n",
    "            pkl.dump(terms, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return terms\n",
    "    \n",
    "\n",
    "def get_tfidf(data, file_name):\n",
    "    print('Converting terms to TF-IDF')\n",
    "    dictionary = Dictionary(data)\n",
    "    corpus = [dictionary.doc2bow(term) for term in data]\n",
    "    num_docs = dictionary.num_docs\n",
    "    num_terms = len(dictionary.keys())\n",
    "    tfidf = TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    corpus_tfidf_dense = corpus2dense(corpus_tfidf, num_terms, num_docs)\n",
    "    cupy_corpus_tfidf = cp.array(corpus_tfidf_dense.T)\n",
    "    save_tfidf(data, file_name)\n",
    "    save_tfidf(data, file_name, 'matrix')\n",
    "    del cupy_corpus_tfidf\n",
    "    \n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65213cd-d779-4354-97c0-0bfa50b88b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in sorted(data_dir.glob('parsed_emails*.pkl'))[1:]:\n",
    "    df = pd.read_pickle(path)\n",
    "    file_name = '_'.join(path.name.split('_')[2:])\n",
    "    messages = df['Message'].dropna().str.lower().to_numpy()\n",
    "    terms = preprocess_terms(messages, file_name)\n",
    "    get_tfidf(terms, file_name)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3568d77-cdd4-4e81-a340-ef65b36dd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in sorted(data_dir.glob('parsed_emails*.pkl'))[1:]:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19494595-b7b3-4fef-94dc-25ad1b274fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in sorted(tfi_dir.glob('*')):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4ebef-e857-4c1b-8335-e80e67ccf552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/home/miguel/Projects/tfm-nlp/data/interim/parsed_emails_chains_gt_1.pkl')\n",
    "messages = df['Message'].dropna().str.lower().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69033e0-d9f5-45a9-92ac-8b21bdd1eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a424a1-913f-43be-a0f8-dafa1d906bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/miguel/Projects/tfm-nlp/data/interim/tfidf/terms_chains_gt_1.pkl', 'rb') as handle:\n",
    "    terms = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfea55a-da3d-4657-a74b-dfa7d3217d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e1661-8380-400c-af64-a4f682fd3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = [list(Counter(term).values()) for term in terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cb9c5-0055-4f9f-840a-0a2352c1679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb263d2-ed17-4ec2-80d0-23b1cb6d4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(terms)\n",
    "corpus = [dictionary.doc2bow(term) for term in terms]\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2c495-3180-4a71-b74c-7ccd9b2d1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3deb0f-ffb2-45ca-a93e-44e1b7bb0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf.save(str(Path(tfi_dir,'corpus_tfidf_terms_chains_gt_1.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c44bbe-873d-4623-8e4c-921a509749ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = pkl.load(str(Path(tfi_dir,'corpus_tfidf_terms_chains_gt_1.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86ba36-967c-48dc-8575-9ce9163ef2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9def97d-5375-45a8-838b-75c3848306ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a463402-bad7-4df8-95b7-6ec42cdf1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[(i, c) for i, c in doc if c > 1] for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681bca7a-d70e-4414-ab0d-80373308343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, freq = zip(*corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068075f1-2f33-4464-8175-482659eba828",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa41a1-b5fa-4d5a-b90c-dbc68c60c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(idx, freq) for zip(*doc) in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cfdab4-3fc6-43b4-b715-f9fec985f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = len(terms)\n",
    "num_terms = len(term_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7555190-1f09-49f5-bb37-7f4adba3d0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "terms_id = [[term_dict[term] for term in doc] for doc in terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7309a-0f40-4600-aaf9-6e6a0e1603c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_ =[' '.join(term) for term in terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ba717-6cdc-4994-8f69-1780183ee950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a89676-f016-4733-8ea7-91f9bf829e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2)\n",
    "X = vectorizer.fit_transform(terms_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb54950-2042-4041-822a-682a60958976",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a6b1be-5422-4cbf-9f80-41ad6c366af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b407b6f-8ac0-41c6-88ac-86e1ebaf1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[0] * X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef293b3-df51-424d-9d7d-513adfb81642",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [list(Counter(term).items()) for term in terms_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739776c-5397-48ff-86bf-02620670d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea8ab1-bdf4-4a6c-87f0-99506ba4728e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ac25e-059d-46b2-8279-3ce98959ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d4f41-af05-4fa9-9024-fcd69901ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c95fa-e589-4285-b415-b64e3667900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf_dense = corpus2dense(corpus_tfidf, num_terms, num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c8afd-7908-4842-a376-5b95c66b0404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c723639-c460-48c0-b888-2ecf12b4f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(terms)\n",
    "corpus = [dictionary.doc2bow(term) for term in terms]\n",
    "num_docs = dictionary.num_docs\n",
    "num_terms = len(dictionary.keys())\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "corpus_tfidf_dense = corpus2dense(corpus_tfidf, num_terms, num_docs)\n",
    "cupy_corpus_tfidf = cp.array(corpus_tfidf_dense.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76f4b0-8108-4f85-a432-8ae012d3b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3f218-f3e7-4c2c-8320-f02fb578a3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
