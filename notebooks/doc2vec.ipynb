{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d4843b6-8ddd-4ea9-afc9-959ac5e35760",
   "metadata": {},
   "source": [
    "# Doc2Vec Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e92c8ba-d0b6-47cc-92e7-39b42c008faa",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ddef202-e674-4533-9cdc-79a1a30e181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dfee3c-b4ed-48ca-92fb-dce562525725",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d80924c-0aaa-4684-ad83-8c547050cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(Path.cwd().parent, 'data/interim')\n",
    "models_dir = Path(Path.cwd().parent, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e9a4d4b-ca21-4c31-ae2f-99125842b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emails(size=int(1e4), seed=42):\n",
    "    with open(Path(data_dir, 'message.pkl'), 'rb') as handle:\n",
    "          messages = pkl.load(handle)\n",
    "    \n",
    "    filtered_emails = [(i, msg) for i, msg, t in messages if not str.isspace(msg) or msg != '']\n",
    "    random.seed(seed)\n",
    "    emails = random.sample(filtered_emails, k=size)\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e3473f-47b7-422b-8b7c-3fd3220b214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = int(2e4)\n",
    "# emails = load_emails(size=size)\n",
    "\n",
    "# Name: sample_emails_seed_size\n",
    "# with open(Path(data_dir, 'sample_emails_42_1e4.pkl'), 'wb') as handle:\n",
    "#     pkl.dump(emails, handle, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d384795-c36e-41ab-8dad-4c462233e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(int(1e4), int(1.01e5), int(0.5e4)):\n",
    "#     emails = load_emails(size=i)\n",
    "#     with open(Path(data_dir, f'sample_emails_42_{i}.pkl'), 'wb') as handle:\n",
    "#         pkl.dump(emails, handle, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bcb52fb-2444-45c7-845a-d682f6e60d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(Path(data_dir, f'sample_emails_42_{int(2e4)}.pkl'), 'rb') as handle:\n",
    "#     emails = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef98c7-1d64-4a09-90dc-8c572dda3c26",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fa01ff0-bbf3-4b11-998b-262c99697c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_docs = [simple_preprocess(emails[i][1]) for i in range(len(emails))]\n",
    "# corpus = [TaggedDocument(doc, [i]) for i, doc in enumerate(tokenized_docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa69dc9-2e31-4056-8114-ff83dd22cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: tagged_docs_seed_size\n",
    "# with open(Path(data_dir, f'tagged_docs_42_{size}.pkl'), 'wb') as handle:\n",
    "#     pkl.dump(corpus, handle, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b958262-0ff2-4926-92d2-32d3399def41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(int(1e4), int(1.01e5), int(0.5e4)):\n",
    "#     with open(Path(data_dir, f'sample_emails_42_{i}.pkl'), 'rb') as handle:\n",
    "#         emails = pkl.load(handle)\n",
    "#     tokenized_docs = [simple_preprocess(emails[i][1]) for i in range(len(emails))]\n",
    "#     corpus = [TaggedDocument(doc, [i]) for i, doc in enumerate(tokenized_docs)]\n",
    "#     with open(Path(data_dir, f'tagged_docs_42_{i}.pkl'), 'wb') as handle:\n",
    "#         pkl.dump(corpus, handle, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd6c716-ff57-4460-87e4-1c5fa4a3aa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with size 10000 saved\n",
      "Model with size 15000 saved\n",
      "Model with size 20000 saved\n",
      "Model with size 25000 saved\n",
      "Model with size 30000 saved\n",
      "Model with size 35000 saved\n",
      "Model with size 40000 saved\n",
      "Model with size 45000 saved\n",
      "Model with size 50000 saved\n",
      "Model with size 55000 saved\n",
      "Model with size 60000 saved\n",
      "Model with size 65000 saved\n",
      "Model with size 70000 saved\n",
      "Model with size 75000 saved\n",
      "Model with size 80000 saved\n",
      "Model with size 85000 saved\n",
      "Model with size 90000 saved\n",
      "Model with size 95000 saved\n",
      "Model with size 100000 saved\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(1e4), int(1.01e5), int(0.5e4)):\n",
    "    with open(Path(data_dir, f'tagged_docs_42_{i}.pkl'), 'rb') as handle:\n",
    "        corpus = pkl.load(handle)\n",
    "    vector_size = 300\n",
    "    window_size = 15\n",
    "    min_count = 1\n",
    "    train_epoch = 20\n",
    "    alpha = 0.25\n",
    "    min_alpha = 1e-5\n",
    "    model = Doc2Vec(vector_size=vector_size,\n",
    "                    window=window_size,\n",
    "                    alpha=alpha, \n",
    "                    min_alpha=min_alpha,\n",
    "                    min_count=min_count,\n",
    "                    epochs=train_epoch,\n",
    "                    dm=0)\n",
    "    model.build_vocab(corpus)\n",
    "    model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    \n",
    "    model.save(str(Path(models_dir, f'dv_42_{i}_300_15_1_20_1e-5.model')))\n",
    "    print(f'Model with size {i} saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fd0746-1553-488e-a8c3-5da524c6ffa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_1e+04\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf9591-88d6-4bd2-adee-a80a51731a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(models_dir, '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7e5d93-13ea-499e-9e8a-fe0555abc757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_size = 300\n",
    "# window_size = 15\n",
    "# min_count = 1\n",
    "# train_epoch = 20\n",
    "# alpha = 0.25\n",
    "# min_alpha = 1e-5\n",
    "# model = Doc2Vec(vector_size=vector_size,\n",
    "#                 window=window_size,\n",
    "#                 alpha=alpha, \n",
    "#                 min_alpha=min_alpha,\n",
    "#                 min_count=min_count,\n",
    "#                 epochs=train_epoch,\n",
    "#                 dm=0)\n",
    "# model.build_vocab(corpus)\n",
    "# model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddda6323-b57e-48b0-9c8e-fd7bb43a4fac",
   "metadata": {},
   "source": [
    "## Assess Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dbebb9-65c5-400f-ad93-c0714238441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(corpus)):\n",
    "    inferred_vector = model.infer_vector(corpus[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])\n",
    "\n",
    "counter = Counter(ranks)\n",
    "print([(i, c, c/len(ranks)*100) for i, c in list(counter.most_common()[:10])])\n",
    "\n",
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(corpus[sims[index][0]].words)))\n",
    "\n",
    "doc_id = random.randint(0, len(corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cada16-f76a-465e-963d-dd4e06b4d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name code: model_vectorsize_window_mincount_epochs_alphamin\n",
    "model.save(str(Path(models_dir, \"dv.model_300_15_1_20_1e-5\")))\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc46446-6cc8-47da-a799-5a57ed486402",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
