{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a8f01d8",
   "metadata": {},
   "source": [
    "# Pre-processing integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e142518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from itertools import groupby \n",
    "\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures as bigram_measures\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e1744f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extreme_vals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extreme_vals' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file = Path('/Volumes', 'tfm', 'raw', 'enron_mails.p')\n",
    "df = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994ac7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132160</th>\n",
       "      <td>forney-j/sent_items/158.</td>\n",
       "      <td>&lt;OMNI&gt;\\n&lt;OMNINotes&gt;&lt;/OMNINotes&gt;\\n\\n&lt;OMNIPAB&gt;PE...</td>\n",
       "      <td>1615558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480942</th>\n",
       "      <td>presto-k/sent_items/1103.</td>\n",
       "      <td>&lt;OMNI&gt;\\n&lt;OMNINotes&gt;&lt;/OMNINotes&gt;\\n\\n&lt;OMNIPAB&gt;PE...</td>\n",
       "      <td>1371385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337694</th>\n",
       "      <td>quigley-d/sent_items/37.</td>\n",
       "      <td>&lt;OMNI&gt;\\n&lt;OMNINotes&gt;\\n    &lt;dbname&gt;C:\\Program Fi...</td>\n",
       "      <td>319984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80043</th>\n",
       "      <td>cash-m/general_research/17.</td>\n",
       "      <td>I am pleased to send you our web-based e-mail ...</td>\n",
       "      <td>215838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308907</th>\n",
       "      <td>dasovich-j/notes_inbox/5594.</td>\n",
       "      <td>=20\\n\\n\\nTelecommunications Reports - January ...</td>\n",
       "      <td>212190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298166</th>\n",
       "      <td>dasovich-j/all_documents/8681.</td>\n",
       "      <td>=20\\n\\n\\nTelecommunications Reports - January ...</td>\n",
       "      <td>212190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331903</th>\n",
       "      <td>crandell-s/sent_items/32.</td>\n",
       "      <td>Delivery Date\\t BORDER 1\\t S DEAL#\\t S PRICE\\t...</td>\n",
       "      <td>210672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293459</th>\n",
       "      <td>dasovich-j/all_documents/8394.</td>\n",
       "      <td>=20\\n=20\\n\\nTelecommunications Reports - Janua...</td>\n",
       "      <td>208766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309367</th>\n",
       "      <td>dasovich-j/notes_inbox/5764.</td>\n",
       "      <td>=20\\n=20\\n\\nTelecommunications Reports - Janua...</td>\n",
       "      <td>208766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296267</th>\n",
       "      <td>dasovich-j/all_documents/11847.</td>\n",
       "      <td>Today's news, and some from the weekend, in th...</td>\n",
       "      <td>187214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "132160         forney-j/sent_items/158.   \n",
       "480942        presto-k/sent_items/1103.   \n",
       "337694         quigley-d/sent_items/37.   \n",
       "80043       cash-m/general_research/17.   \n",
       "308907     dasovich-j/notes_inbox/5594.   \n",
       "298166   dasovich-j/all_documents/8681.   \n",
       "331903        crandell-s/sent_items/32.   \n",
       "293459   dasovich-j/all_documents/8394.   \n",
       "309367     dasovich-j/notes_inbox/5764.   \n",
       "296267  dasovich-j/all_documents/11847.   \n",
       "\n",
       "                                                     text   length  \n",
       "132160  <OMNI>\\n<OMNINotes></OMNINotes>\\n\\n<OMNIPAB>PE...  1615558  \n",
       "480942  <OMNI>\\n<OMNINotes></OMNINotes>\\n\\n<OMNIPAB>PE...  1371385  \n",
       "337694  <OMNI>\\n<OMNINotes>\\n    <dbname>C:\\Program Fi...   319984  \n",
       "80043   I am pleased to send you our web-based e-mail ...   215838  \n",
       "308907  =20\\n\\n\\nTelecommunications Reports - January ...   212190  \n",
       "298166  =20\\n\\n\\nTelecommunications Reports - January ...   212190  \n",
       "331903  Delivery Date\\t BORDER 1\\t S DEAL#\\t S PRICE\\t...   210672  \n",
       "293459  =20\\n=20\\n\\nTelecommunications Reports - Janua...   208766  \n",
       "309367  =20\\n=20\\n\\nTelecommunications Reports - Janua...   208766  \n",
       "296267  Today's news, and some from the weekend, in th...   187214  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'] = df['text'].apply(len)\n",
    "Q1 = df['length'].quantile(0.25)\n",
    "Q3 = df['length'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# df.loc[df['length'] > (Q3 + 15 * IQR),:]\n",
    "df.sort_values(by=['length'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec21e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_vals = [132160, 480942, 337694]\n",
    "df.drop(extreme_vals, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b4a94a",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be3ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(text, wordpunct=False, stop_words=False):\n",
    "    \n",
    "    stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "    \n",
    "    #stop = set(stopwords.words('english'))\n",
    "    \n",
    "    if wordpunct:\n",
    "        if stop_words:\n",
    "            tokens = [w for w in wordpunct_tokenize(text.lower()) if w not in stop]\n",
    "        else:\n",
    "            tokens = wordpunct_tokenize(text)\n",
    "    else:\n",
    "        if stop_words:\n",
    "            tokens = [w for w in word_tokenize(text.lower()) if w not in stop]\n",
    "        else:\n",
    "            tokens = word_tokenize(text)\n",
    "    \n",
    "    return tokens\n",
    "            \n",
    "\n",
    "# def get_punct_tokens(text, w):\n",
    "#     tokens = wordpunct_tokenize(text)\n",
    "    \n",
    "#     return tokens\n",
    "\n",
    "\n",
    "# def get_tokens(text):\n",
    "#     tokens = word_tokenize(text)\n",
    "    \n",
    "#     return tokens\n",
    "\n",
    "\n",
    "def get_bigrams(text):\n",
    "    bigram = nltk.bigrams(text)\n",
    "    \n",
    "    return list(bigram)\n",
    "\n",
    "\n",
    "def get_freqs(text):\n",
    "    freq_dist = FreqDist(word.lower() for word in text)\n",
    "    \n",
    "    return freq_dist\n",
    "\n",
    "\n",
    "def save_data(column):\n",
    "    data_path = Path('output', f'email_nltk_{column}.pkl')\n",
    "    if data_path.is_file():\n",
    "        print('already saved')\n",
    "    else:\n",
    "        print(f'saving {column} ...')\n",
    "        df.loc[:,['id', column]].to_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b09f3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [----------------------, forwarded, maria, san...\n",
       "1    [----------------------, forwarded, judy, hern...\n",
       "2    [----------------------, forwarded, judy, hern...\n",
       "3                        [received, message, kat, !!!]\n",
       "4                                             [fyi, .]\n",
       "5    [nutcracker, tickets, fabulous, seats, final, ...\n",
       "6    [content, -, transfer, -, encoding, :, quoted,...\n",
       "7    [----------------------, forwarded, eve, pucke...\n",
       "8    [daily, blessing, http, ://, www, ., daily, -,...\n",
       "9    [----------------------, forwarded, judy, hern...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head(10).apply(get_tokens, args=(True, True,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f4c18",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bbd550",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['tkp'] = df['text'].apply(get_punct_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a8c53c",
   "metadata": {},
   "source": [
    "## word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['tkn'] = df['text'].apply(get_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47a7fe",
   "metadata": {},
   "source": [
    "## Collocations and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_tkp'] = df['tkp'].apply(get_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_tkn'] = df['tkn'].apply(get_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['bg_tkp'] = df['tkp'].apply(get_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['bg_tkn'] = df['tkn'].apply(get_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_bg_tkp'] = df['bg_tkp'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903438e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_bg_tkn'] = df['bg_tkn'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bab53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['cl_tkp'] = df.apply(lambda row: BigramCollocationFinder(row.fq_tkp, row.fq_bg_tkp), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29df15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['cl_tkn'] = df.apply(lambda row: BigramCollocationFinder(row.fq_tkn, row.fq_bg_tkn), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['fq_tkp',\n",
    "        'fq_tkn',\n",
    "        'bg_tkp',\n",
    "        'bg_tkn',\n",
    "        'fq_bg_tkp',\n",
    "        'fq_bg_tkn',\n",
    "        'cl_tkp',\n",
    "        'cl_tkn']\n",
    "for col in cols:\n",
    "    save_data(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=cols,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef22f7",
   "metadata": {},
   "source": [
    "## Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b9fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16767bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['lm_wn_tkp'] = df.apply(lambda row: [wn.lemmatize(word) for word in row.tkp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['lm_wn_tkn'] = df.apply(lambda row: [wn.lemmatize(word) for word in row.tkn], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24649533",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_lm_wn_tkp'] = df['lm_wn_tkp'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa992ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_lm_wn_tkn'] = df['lm_wn_tkn'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c6a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['lm_wn_tkp',\n",
    "        'lm_wn_tkn',\n",
    "        'fq_lm_wn_tkp',\n",
    "        'fq_lm_wn_tkn']\n",
    "for col in cols:\n",
    "    save_data(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb02a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d1626f",
   "metadata": {},
   "source": [
    "## Stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a374dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "ss = nltk.SnowballStemmer(language = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['st_ps_tkp'] = df.apply(lambda row: [ps.stem(word) for word in row.tkp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['st_ps_tkn'] = df.apply(lambda row: [ps.stem(word) for word in row.tkn], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_st_ps_tkp'] = df['st_ps_tkp'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_st_ps_tkn'] = df['st_ps_tkn'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dcb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['st_ss_tkp'] = df.apply(lambda row: [ss.stem(word) for word in row.tkp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['st_ss_tkn'] = df.apply(lambda row: [ss.stem(word) for word in row.tkn], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_st_ss_tkp'] = df['st_ss_tkp'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41fe341",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_st_ss_tkn'] = df['st_ss_tkn'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ac38d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['st_ps_tkp',\n",
    "        'st_ps_tkn',\n",
    "        'fq_st_ps_tkp',\n",
    "        'fq_st_ps_tkn',\n",
    "        'st_ss_tkp',\n",
    "        'st_ss_tkn',\n",
    "        'fq_st_ss_tkp',\n",
    "        'fq_st_ss_tkn']\n",
    "for col in cols:\n",
    "    save_data(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=cols, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miri] *",
   "language": "python",
   "name": "conda-env-miri-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
