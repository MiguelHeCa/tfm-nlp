{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce47a64",
   "metadata": {},
   "source": [
    "# Converting parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcec8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures as bigram_measures\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5614e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file = Path('input', 'enron_mails.p')\n",
    "df = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punct_tokens(text):\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def get_tokens(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def get_bigrams(text):\n",
    "    bigram = nltk.bigrams(text)\n",
    "    \n",
    "    return list(bigram)\n",
    "\n",
    "\n",
    "def get_freqs(text):\n",
    "    freq_dist = FreqDist(word.lower() for word in text)\n",
    "    \n",
    "    return freq_dist\n",
    "\n",
    "\n",
    "def save_data(column):\n",
    "    data_path = Path('output', f'email_nltk_{column}.pkl')\n",
    "    if data_path.is_file():\n",
    "        print('already saved')\n",
    "    else:\n",
    "        print(f'saving {column} ...')\n",
    "        df.loc[:,['id', column]].to_pickle(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f4c18",
   "metadata": {},
   "source": [
    "## Wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bbd550",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['tkp'] = df['text'].apply(get_punct_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a8c53c",
   "metadata": {},
   "source": [
    "## word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['tkn'] = df['text'].apply(get_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47a7fe",
   "metadata": {},
   "source": [
    "## Collocations and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_tkp'] = df['tkp'].apply(get_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_tkn'] = df['tkn'].apply(get_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['bg_tkp'] = df['tkp'].apply(get_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['bg_tkn'] = df['tkn'].apply(get_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_bg_tkp'] = df['bg_tkp'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903438e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_bg_tkn'] = df['bg_tkn'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bab53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['cl_tkp'] = df.apply(lambda row: BigramCollocationFinder(row.fq_tkp, row.fq_bg_tkp), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29df15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['cl_tkn'] = df.apply(lambda row: BigramCollocationFinder(row.fq_tkn, row.fq_bg_tkn), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['fq_tkp',\n",
    "        'fq_tkn',\n",
    "        'bg_tkp',\n",
    "        'bg_tkn',\n",
    "        'fq_bg_tkp',\n",
    "        'fq_bg_tkn',\n",
    "        'cl_tkp',\n",
    "        'cl_tkn']\n",
    "for col in cols:\n",
    "    save_data(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=cols,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef22f7",
   "metadata": {},
   "source": [
    "## Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b9fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16767bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['lm_wn_tkp'] = df.apply(lambda row: [wn.lemmatize(word) for word in row.tkp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['lm_wn_tkn'] = df.apply(lambda row: [wn.lemmatize(word) for word in row.tkn], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24649533",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_lm_wn_tkp'] = df['lm_wn_tkp'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa992ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_lm_wn_tkn'] = df['lm_wn_tkn'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c6a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['lm_wn_tkp',\n",
    "        'lm_wn_tkn',\n",
    "        'fq_lm_wn_tkp',\n",
    "        'fq_lm_wn_tkn']\n",
    "for col in cols:\n",
    "    save_data(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb02a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d1626f",
   "metadata": {},
   "source": [
    "## Stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a374dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "ss = nltk.SnowballStemmer(language = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['st_ps_tkp'] = df.apply(lambda row: [ps.stem(word) for word in row.tkp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['st_ps_tkn'] = df.apply(lambda row: [ps.stem(word) for word in row.tkn], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_st_ps_tkp'] = df['st_ps_tkp'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_st_ps_tkn'] = df['st_ps_tkn'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dcb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['st_ss_tkp'] = df.apply(lambda row: [ss.stem(word) for word in row.tkp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['st_ss_tkn'] = df.apply(lambda row: [ss.stem(word) for word in row.tkn], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_st_ss_tkp'] = df['st_ss_tkp'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41fe341",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['fq_st_ss_tkn'] = df['st_ss_tkn'].apply(FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ac38d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['st_ps_tkp',\n",
    "        'st_ps_tkn',\n",
    "        'fq_st_ps_tkp',\n",
    "        'fq_st_ps_tkn',\n",
    "        'st_ss_tkp',\n",
    "        'st_ss_tkn',\n",
    "        'fq_st_ss_tkp',\n",
    "        'fq_st_ss_tkn']\n",
    "for col in cols:\n",
    "    save_data(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe34a70",
   "metadata": {},
   "source": [
    "## Taggers and PoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf038b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27b348df",
   "metadata": {},
   "source": [
    "## Export only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in df.columns[2:]:\n",
    "#     data_path = Path('output', f'email_nltk_{column}.pkl')\n",
    "#     if data_path.is_file():\n",
    "#         print('already saved')\n",
    "#     else:\n",
    "#         print(f'saving {column} ...')\n",
    "#         df.loc[:,['id', column]].to_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66cd594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miri] *",
   "language": "python",
   "name": "conda-env-miri-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
